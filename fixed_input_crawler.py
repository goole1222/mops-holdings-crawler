#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤è¾“å…¥æ¡†å®šä½çš„çˆ¬è™« - é’ˆå¯¹æ­£ç¡®çš„è¡¨å•ç»“æ„
"""

import time
import logging
import pandas as pd
import urllib3
import requests
import csv
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
import os
import glob
from datetime import datetime
from typing import Optional

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class FixedInputCrawler:
    def __init__(self):
        """åˆå§‹åŒ–ä¿®å¤è¾“å…¥æ¡†çš„çˆ¬è™«"""
        self.setup_logging()
        self.driver = None
        self.all_data = {}
        self.failed_codes = []
        self.processed_count = 0  # å·²è™•ç†çš„è‚¡ç¥¨æ•¸é‡è¨ˆæ•¸å™¨

        # è®¾ç½®ä¸‹è½½ç›®å½•
        self.download_dir = os.path.join(os.getcwd(), "downloads")
        if not os.path.exists(self.download_dir):
            os.makedirs(self.download_dir)
            self.logger.info(f"ğŸ“ åˆ›å»ºä¸‹è½½ç›®å½•: {self.download_dir}")

        # å¯¼èˆªä¿¡æ¯
        self.main_url = "https://mops.twse.com.tw/mops/#/web/home"
        self.target_menu_text = "è‘£ç›£äº‹æŒè‚¡é¤˜é¡"

    def read_stock_codes(self, path="è‚¡ç¥¨ä»£è™Ÿ.txt"):
        """è®€å–è‚¡ç¥¨ä»£è™Ÿæ¸…å–®æ–‡ä»¶"""
        import re
        codes = []
        try:
            with open(path, "r", encoding="utf-8") as f:
                for i, line in enumerate(f):
                    s = line.strip()
                    if not s or i == 0 and ("ä»£è™Ÿ" in s or "code" in s.lower()):
                        continue
                    s = re.sub(r"[^\d]", "", s)  # åªç•™æ•¸å­—
                    if s:
                        codes.append(s)
        except Exception as e:
            self.logger.error(f"âŒ è®€å–ä»£è™Ÿæ¸…å–®å¤±æ•—: {e}")
            return []

        # å»é‡ï¼Œä¿ç•™åŸé †åº
        seen, uniq = set(), []
        for c in codes:
            if c not in seen:
                seen.add(c)
                uniq.append(c)
        self.logger.info(f"ğŸ“‹ è®€åˆ° {len(uniq)} å€‹ä»£è™Ÿ")
        return uniq

    def append_to_master_excel(self, out_path, df_chunk):
        """
        å°‡ df_chunkï¼ˆæ¬„ä½å¿…ç‚º è‚¡ç¥¨ä»£è™Ÿ, å§“å, ç›®å‰æŒè‚¡ï¼‰è¿½åŠ åˆ° out_path çš„ã€Œåˆä½µã€å·¥ä½œè¡¨ã€‚
        è‹¥æª”æ¡ˆä¸å­˜åœ¨æˆ–æ²’æœ‰ã€Œåˆä½µã€ï¼Œå°±æ–°å»ºã€‚
        """
        import pandas as pd
        from openpyxl.styles import Font, PatternFill, Alignment
        import os

        df_chunk = df_chunk[["è‚¡ç¥¨ä»£è™Ÿ","å§“å","ç›®å‰æŒè‚¡"]].copy()

        if not os.path.exists(out_path):
            # æ–°å»ºï¼šç›´æ¥å¯«å…¥ä¸¦å¥—è¡¨é ­æ¨£å¼
            with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
                df_chunk.to_excel(writer, sheet_name="åˆä½µ", index=False)
                ws = writer.sheets["åˆä½µ"]
                header_font = Font(bold=True, color="FFFFFF")
                header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                for cell in ws[1]:
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = Alignment(horizontal="center")
                ws.column_dimensions['A'].width = 14
                ws.column_dimensions['B'].width = 30
                ws.column_dimensions['C'].width = 20
            self.logger.info(f"âœ… æ–°å»º Excel ä¸¦å¯«å…¥: {out_path}")
            return

        # å·²å­˜åœ¨ï¼šè®€èˆŠåˆä½µã€åˆä½µå¾Œæ•´å¼µé‡å¯«
        try:
            old = pd.read_excel(out_path, sheet_name="åˆä½µ", engine="openpyxl")
        except Exception:
            old = pd.DataFrame(columns=["è‚¡ç¥¨ä»£è™Ÿ","å§“å","ç›®å‰æŒè‚¡"])

        merged = pd.concat([old, df_chunk], ignore_index=True)
        # ç§»é™¤æ˜é¡¯è¡¨é ­æ®˜ç•™èˆ‡é‡è¤‡
        merged = merged.dropna(subset=["å§“å"])
        merged = merged[~merged["å§“å"].astype(str).str.contains("å§“å|åç¨±", na=False)]
        merged = merged.drop_duplicates(subset=["è‚¡ç¥¨ä»£è™Ÿ","å§“å"], keep="last")

        with pd.ExcelWriter(out_path, engine="openpyxl", mode="w") as writer:
            merged.to_excel(writer, sheet_name="åˆä½µ", index=False)
            ws = writer.sheets["åˆä½µ"]
            header_font = Font(bold=True, color="FFFFFF")
            header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
            for cell in ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = Alignment(horizontal="center")
            ws.column_dimensions['A'].width = 14
            ws.column_dimensions['B'].width = 30
            ws.column_dimensions['C'].width = 20
        self.logger.info(f"âœ… è¿½åŠ è³‡æ–™è‡³ Excel: {out_path} (ç›®å‰å…± {len(merged)} ç­†)")

    def load_processed_codes(self, path="processed_codes.txt"):
        """è¼‰å…¥å·²è™•ç†çš„ä»£è™Ÿæ¸…å–®"""
        import os
        if not os.path.exists(path):
            return set()
        with open(path, "r", encoding="utf-8") as f:
            return set([ln.strip() for ln in f if ln.strip()])

    def append_processed_code(self, code, path="processed_codes.txt"):
        """å°‡å·²è™•ç†çš„ä»£è™Ÿè¿½åŠ åˆ°æ¸…å–®"""
        with open(path, "a", encoding="utf-8") as f:
            f.write(str(code).strip() + "\n")

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(message)s',
            handlers=[
                logging.FileHandler('fixed_input_crawler.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def setup_chrome(self):
        """è®¾ç½®Chromeé€‰é¡¹ - ä½¿ç”¨æ›´ç©©å®šçš„ headless æ¨¡å¼"""
        options = Options()
        # åŸºç¤ç©©å®šæ€§è¨­å®š
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--headless=new')  # ä½¿ç”¨æ–°ç‰ˆ headless æ¨¡å¼
        options.add_argument('--disable-features=VizDisplayCompositor')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_argument('--disable-images')  # é—œé–‰åœ–ç‰‡è¼‰å…¥
        options.add_argument('--disable-javascript')
        options.add_argument('--disable-background-timer-throttling')
        options.add_argument('--disable-renderer-backgrounding')
        options.add_argument('--disable-backgrounding-occluded-windows')
        options.add_argument('--ignore-certificate-errors')
        options.add_argument('--ignore-ssl-errors')
        options.add_argument('--allow-running-insecure-content')
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--log-level=3')
        options.add_experimental_option('excludeSwitches', ['enable-logging'])
        # è¨˜æ†¶é«”å„ªåŒ–
        options.add_argument('--max_old_space_size=4096')
        options.add_argument('--memory-pressure-off')

        # è®¾ç½®è‡ªåŠ¨ä¸‹è½½é€‰é¡¹
        prefs = {
            "download.default_directory": self.download_dir,
            "download.prompt_for_download": False,
            "download.directory_upgrade": True,
            "safebrowsing.enabled": True,
            "profile.default_content_setting_values.automatic_downloads": 1,
            "profile.default_content_setting_values.popups": 1
        }
        options.add_experimental_option("prefs", prefs)

        return options

    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨"""
        try:
            options = self.setup_chrome()
            self.driver = webdriver.Chrome(options=options)
            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)
            self.logger.info("âœ… Chromeæµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def restart_driver(self):
        """é‡å•Ÿç€è¦½å™¨é©…å‹•"""
        try:
            self.logger.info("â™»ï¸ æ­£åœ¨é‡å•Ÿç€è¦½å™¨...")
            if self.driver:
                try:
                    self.driver.quit()
                except:
                    pass
                self.driver = None

            # çŸ­æš«ç­‰å¾…ç¢ºä¿è³‡æºé‡‹æ”¾
            time.sleep(2)

            # é‡æ–°åˆå§‹åŒ–
            if self.init_driver():
                self.logger.info("â™»ï¸ ç€è¦½å™¨é‡å•ŸæˆåŠŸ")
                return True
            else:
                self.logger.error("â™»ï¸ ç€è¦½å™¨é‡å•Ÿå¤±æ•—")
                return False
        except Exception as e:
            self.logger.error(f"â™»ï¸ é‡å•Ÿç€è¦½å™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False

    def check_driver_alive(self):
        """æª¢æŸ¥ç€è¦½å™¨é©…å‹•æ˜¯å¦ä»å¯ç”¨"""
        try:
            if self.driver is None:
                return False
            # å˜—è©¦ç²å–ç•¶å‰URLä¾†æ¸¬è©¦é€£æ¥
            _ = self.driver.current_url
            return True
        except (WebDriverException, Exception):
            return False

    def ensure_single_tab(self):
        """ç¢ºä¿åªæœ‰ä¸€å€‹åˆ†é é–‹å•Ÿ"""
        try:
            if self.driver and len(self.driver.window_handles) > 1:
                # é—œé–‰é™¤äº†ç¬¬ä¸€å€‹ä¹‹å¤–çš„æ‰€æœ‰åˆ†é 
                main_handle = self.driver.window_handles[0]
                for handle in self.driver.window_handles[1:]:
                    self.driver.switch_to.window(handle)
                    self.driver.close()
                # åˆ‡å›ä¸»åˆ†é 
                self.driver.switch_to.window(main_handle)
                self.logger.info("ğŸ—‚ï¸ å·²æ¸…ç†å¤šé¤˜åˆ†é ï¼Œä¿ç•™å–®ä¸€åˆ†é ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ¸…ç†åˆ†é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    def navigate_to_target_page(self):
        """å¯¼èˆªåˆ°è‘£ç›£äº‹æŒè‚¡é¤˜é¡é¡µé¢"""
        try:
            # æ­¥éª¤1: è¿›å…¥ä¸»é¡µ
            self.logger.info(f"ğŸ“– æ­¥éª¤1: è®¿é—®ä¸»é¡µ {self.main_url}")
            self.driver.get(self.main_url)
            time.sleep(5)

            self.logger.info(f"   é¡µé¢æ ‡é¢˜: {self.driver.title}")

            # æ­¥éª¤2: ç‚¹å‡»è‘£ç›£äº‹æŒè‚¡é¤˜é¡èœå•
            self.logger.info(f"ğŸ” æ­¥éª¤2: å¯»æ‰¾'{self.target_menu_text}'èœå•")

            menu_selectors = [
                f"//a[contains(text(), '{self.target_menu_text}')]",
                f"//span[contains(text(), '{self.target_menu_text}')]",
                f"//div[contains(text(), '{self.target_menu_text}')]",
                f"//*[contains(text(), '{self.target_menu_text}')]"
            ]

            menu_element = None
            for selector in menu_selectors:
                try:
                    menu_elements = self.driver.find_elements(By.XPATH, selector)
                    for element in menu_elements:
                        if element.is_displayed() and element.is_enabled():
                            menu_element = element
                            self.logger.info(f"âœ… æ‰¾åˆ°èœå•é¡¹: {selector}")
                            break
                    if menu_element:
                        break
                except:
                    continue

            if not menu_element:
                self.logger.error(f"âŒ æœªæ‰¾åˆ°'{self.target_menu_text}'èœå•é¡¹")
                return False

            # ç‚¹å‡»èœå•
            self.logger.info(f"ğŸ‘† ç‚¹å‡»'{self.target_menu_text}'èœå•")
            try:
                menu_element.click()
            except:
                self.driver.execute_script("arguments[0].click();", menu_element)

            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(8)

            # éªŒè¯æ˜¯å¦åˆ°è¾¾æ­£ç¡®é¡µé¢
            current_url = self.driver.current_url
            page_source = self.driver.page_source

            if "è‘£ç›£äº‹æŒè‚¡é¤˜é¡" in page_source or "æŸ¥è©¢æ¢ä»¶" in page_source:
                self.logger.info("âœ… æˆåŠŸå¯¼èˆªåˆ°è‘£ç›£äº‹æŒè‚¡é¤˜é¡é¡µé¢")
                return True
            else:
                self.logger.error("âŒ æœªèƒ½æˆåŠŸå¯¼èˆªåˆ°ç›®æ ‡é¡µé¢")
                return False

        except Exception as e:
            self.logger.error(f"âŒ å¯¼èˆªå¤±è´¥: {e}")
            return False

    def find_and_fill_company_input(self, stock_code):
        """å¯»æ‰¾å¹¶å¡«å†™å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±è¾“å…¥æ¡†"""
        try:
            self.logger.info(f"ğŸ“ æ­¥éª¤3: å¯»æ‰¾'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±'è¾“å…¥æ¡†")

            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            time.sleep(3)

            # å¤šç§ç­–ç•¥å¯»æ‰¾è¾“å…¥æ¡†
            input_strategies = [
                # ç­–ç•¥1: é€šè¿‡æ ‡ç­¾æ–‡å­—å¯»æ‰¾ç›¸é‚»çš„input
                "//label[contains(text(), 'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±')]/following-sibling::input",
                "//label[contains(text(), 'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±')]/..//input",

                # ç­–ç•¥2: é€šè¿‡placeholderå¯»æ‰¾
                "//input[contains(@placeholder, '1101')]",
                "//input[contains(@placeholder, 'ä¾‹å¦‚')]",

                # ç­–ç•¥3: é€šè¿‡è¡¨å•ç»“æ„å¯»æ‰¾
                "//div[contains(text(), 'æŸ¥è©¢æ¢ä»¶')]//input",
                "//form//input[contains(@placeholder, '1101')]",

                # ç­–ç•¥4: é€šè¿‡textå†…å®¹å¯»æ‰¾é™„è¿‘çš„input
                "//text()[contains(., 'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±')]/../..//input",
                "//*[contains(text(), 'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±')]/following::input[1]",
                "//*[contains(text(), 'å…¬å¸ä»£è™Ÿæˆ–ç°¡ç¨±')]/..//input",

                # ç­–ç•¥5: æŸ¥æ‰¾è¡¨å•ä¸­çš„æ‰€æœ‰textç±»å‹input
                "//div[contains(@class, 'form') or contains(@class, 'query')]//input[@type='text']",
                "//input[@type='text']",

                # ç­–ç•¥6: é€šè¿‡nameæˆ–idå±æ€§
                "//input[contains(@name, 'co_id') or contains(@name, 'company')]",
                "//input[contains(@id, 'co_id') or contains(@id, 'company')]"
            ]

            input_element = None
            found_strategy = None

            for i, strategy in enumerate(input_strategies, 1):
                try:
                    self.logger.info(f"   å°è¯•ç­–ç•¥{i}: {strategy[:50]}...")
                    elements = self.driver.find_elements(By.XPATH, strategy)

                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            # éªŒè¯è¿™æ˜¯å¦æ˜¯æ­£ç¡®çš„è¾“å…¥æ¡†
                            placeholder = element.get_attribute('placeholder') or ""
                            name = element.get_attribute('name') or ""
                            id_attr = element.get_attribute('id') or ""

                            self.logger.info(f"   æ‰¾åˆ°è¾“å…¥æ¡†: placeholder='{placeholder}', name='{name}', id='{id_attr}'")

                            # å¦‚æœplaceholderåŒ…å«'1101'æˆ–å…¶ä»–ç›¸å…³å…³é”®è¯ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯æ­£ç¡®çš„è¾“å…¥æ¡†
                            if ('1101' in placeholder or 'ä¾‹å¦‚' in placeholder or
                                'co_id' in name.lower() or 'company' in name.lower()):
                                input_element = element
                                found_strategy = strategy
                                self.logger.info(f"âœ… æ‰¾åˆ°ç›®æ ‡è¾“å…¥æ¡†ï¼ä½¿ç”¨ç­–ç•¥{i}")
                                break

                            # å¦‚æœæ²¡æœ‰æ˜ç¡®æ ‡è¯†ï¼Œä½†æ˜¯åœ¨æŸ¥è¯¢è¡¨å•ä¸­ï¼Œä¹Ÿå¯èƒ½æ˜¯æ­£ç¡®çš„
                            if not input_element:
                                input_element = element
                                found_strategy = strategy
                                self.logger.info(f"âœ… æ‰¾åˆ°å¯èƒ½çš„è¾“å…¥æ¡†ï¼Œä½¿ç”¨ç­–ç•¥{i}")

                    if input_element:
                        break

                except Exception as e:
                    self.logger.info(f"   ç­–ç•¥{i}å¤±è´¥: {e}")
                    continue

            if not input_element:
                self.logger.error("âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªæ‰¾åˆ°è¾“å…¥æ¡†")

                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé¡µé¢ä¸­æ‰€æœ‰inputå…ƒç´ 
                self.logger.info("ğŸ” è°ƒè¯•ä¿¡æ¯ - é¡µé¢ä¸­æ‰€æœ‰inputå…ƒç´ :")
                try:
                    all_inputs = self.driver.find_elements(By.TAG_NAME, "input")
                    for j, inp in enumerate(all_inputs):
                        try:
                            if inp.is_displayed():
                                placeholder = inp.get_attribute('placeholder') or ""
                                name = inp.get_attribute('name') or ""
                                type_attr = inp.get_attribute('type') or ""
                                self.logger.info(f"   Input{j+1}: type='{type_attr}', placeholder='{placeholder}', name='{name}'")
                        except:
                            pass
                except:
                    pass

                return False

            # å¡«å†™è‚¡ç¥¨ä»£å·
            self.logger.info(f"ğŸ“ åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥è‚¡ç¥¨ä»£å·: {stock_code}")

            try:
                # æ¸…ç©ºè¾“å…¥æ¡†
                input_element.clear()
                time.sleep(1)

                # è¾“å…¥è‚¡ç¥¨ä»£å·
                input_element.send_keys(stock_code)
                time.sleep(1)

                # éªŒè¯è¾“å…¥
                current_value = input_element.get_attribute('value')
                if current_value == stock_code:
                    self.logger.info(f"âœ… è‚¡ç¥¨ä»£å·è¾“å…¥æˆåŠŸ: {current_value}")
                    return True
                else:
                    self.logger.warning(f"âš ï¸ è¾“å…¥éªŒè¯å¤±è´¥: æœŸæœ›'{stock_code}', å®é™…'{current_value}'")
                    return True  # ä»ç„¶ç»§ç»­ï¼Œå¯èƒ½æ˜¯æ˜¾ç¤ºå»¶è¿Ÿ

            except Exception as e:
                self.logger.error(f"âŒ è¾“å…¥è‚¡ç¥¨ä»£å·å¤±è´¥: {e}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ å¯»æ‰¾è¾“å…¥æ¡†è¿‡ç¨‹å¤±è´¥: {e}")
            return False

    def click_query_button(self):
        """ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®"""
        try:
            self.logger.info("ğŸ” æ­¥éª¤4: å¯»æ‰¾å¹¶ç‚¹å‡»'æŸ¥è©¢'æŒ‰é’®")

            # å¤šç§ç­–ç•¥å¯»æ‰¾æŸ¥è¯¢æŒ‰é’®
            button_strategies = [
                # ç­–ç•¥1: ç›´æ¥æŸ¥æ‰¾æŸ¥è¯¢æŒ‰é’®
                "//button[contains(text(), 'æŸ¥è©¢')]",
                "//input[@value='æŸ¥è©¢']",
                "//button[contains(@class, 'query') or contains(@class, 'search')]",

                # ç­–ç•¥2: åœ¨è¡¨å•ä¸­æŸ¥æ‰¾æäº¤æŒ‰é’®
                "//form//button[@type='submit']",
                "//form//input[@type='submit']",

                # ç­–ç•¥3: æŸ¥æ‰¾è“è‰²æˆ–ä¸»è¦æŒ‰é’®
                "//button[contains(@class, 'btn-primary') or contains(@class, 'primary')]",
                "//button[contains(@class, 'blue') or contains(@style, 'blue')]",

                # ç­–ç•¥4: åœ¨æŸ¥è¯¢æ¡ä»¶é™„è¿‘æŸ¥æ‰¾æŒ‰é’®
                "//div[contains(text(), 'æŸ¥è©¢æ¢ä»¶')]//button",
                "//*[contains(text(), 'æŸ¥è©¢')]"
            ]

            button_element = None
            for i, strategy in enumerate(button_strategies, 1):
                try:
                    self.logger.info(f"   å°è¯•æŒ‰é’®ç­–ç•¥{i}: {strategy[:50]}...")
                    elements = self.driver.find_elements(By.XPATH, strategy)

                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            button_text = element.text or element.get_attribute('value') or ""
                            self.logger.info(f"   æ‰¾åˆ°æŒ‰é’®: æ–‡å­—='{button_text}'")

                            if 'æŸ¥è©¢' in button_text or element.get_attribute('type') == 'submit':
                                button_element = element
                                self.logger.info(f"âœ… æ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®ï¼ä½¿ç”¨ç­–ç•¥{i}")
                                break

                    if button_element:
                        break

                except Exception as e:
                    self.logger.info(f"   æŒ‰é’®ç­–ç•¥{i}å¤±è´¥: {e}")
                    continue

            if not button_element:
                self.logger.error("âŒ æœªæ‰¾åˆ°æŸ¥è¯¢æŒ‰é’®")
                return False

            # ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
            self.logger.info("ğŸ‘† ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®")
            try:
                button_element.click()
                self.logger.info("   ç›´æ¥ç‚¹å‡»æˆåŠŸ")
            except:
                try:
                    self.driver.execute_script("arguments[0].click();", button_element)
                    self.logger.info("   JavaScriptç‚¹å‡»æˆåŠŸ")
                except:
                    self.logger.error("   æ‰€æœ‰ç‚¹å‡»æ–¹å¼éƒ½å¤±è´¥")
                    return False

            # ç­‰å¾…æŸ¥è¯¢ç»“æœ
            self.logger.info("â³ ç­‰å¾…æŸ¥è¯¢ç»“æœåŠ è½½...")
            time.sleep(8)

            return True

        except Exception as e:
            self.logger.error(f"âŒ ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®å¤±è´¥: {e}")
            return False

    def _requests_session_from_driver(self):
        """å°‡ Selenium cookies è½‰æˆ requests å¯ç”¨çš„ session"""
        s = requests.Session()
        for c in self.driver.get_cookies():
            s.cookies.set(c["name"], c["value"], domain=c.get("domain"))
        # å¸¶ä¸Š UA
        s.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        })
        return s

    def clear_old_downloads(self):
        """æ¸…é™¤ä¸‹è½½ç›®å½•ä¸­çš„æ—§CSVæ–‡ä»¶"""
        try:
            csv_files = glob.glob(os.path.join(self.download_dir, "*.csv"))
            crdownload_files = glob.glob(os.path.join(self.download_dir, "*.crdownload"))

            all_files_to_remove = csv_files + crdownload_files
            removed_count = 0

            for file_path in all_files_to_remove:
                try:
                    os.remove(file_path)
                    removed_count += 1
                    self.logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {os.path.basename(file_path)}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {os.path.basename(file_path)}: {e}")

            if removed_count > 0:
                self.logger.info(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªæ–‡ä»¶")
            else:
                self.logger.info("â„¹ï¸ ä¸‹è½½ç›®å½•ä¸­æ— éœ€æ¸…ç†çš„æ–‡ä»¶")

        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç†ä¸‹è½½ç›®å½•å¤±è´¥: {e}")

    def download_csv_and_parse(self):
        import time, os, glob
        from datetime import datetime
        self.logger.info("ğŸ“¥ æ­¥éª¤4a: å˜—è©¦ä¸‹è¼‰CSVæª”æ¡ˆ")
        self.clear_old_downloads()
        time.sleep(1)

        # 1) å…ˆæ‰¾ a[href*=.csv] æˆ– ä¸‹è¼‰CSV æŒ‰éˆ•
        candidates = []
        xpaths = [
            "//a[contains(@href,'.csv')]",
            "//button[contains(normalize-space(.),'ä¸‹è¼‰CSV')]",
            "//span[contains(normalize-space(.),'ä¸‹è¼‰CSV')]/ancestor::a",
            "//span[contains(normalize-space(.),'ä¸‹è¼‰CSV')]/ancestor::button"
        ]
        for xp in xpaths:
            els = self.driver.find_elements(By.XPATH, xp)
            for el in els:
                if el.is_displayed() and el.is_enabled():
                    candidates.append(el)
        if not candidates:
            self.logger.warning("âš ï¸ æœªæ‰¾åˆ°CSVä¸‹è¼‰å…ƒç´ ")
            return None

        # 2) æœ‰ href çš„è©±ï¼Œç›´æ¥ç”¨ requests ä¸‹è¼‰
        for el in candidates:
            href = el.get_attribute("href")
            if href and ".csv" in href.lower():
                try:
                    self.logger.info(f"ğŸ”— ç›´æ¥è«‹æ±‚ CSV: {href[:120]}...")
                    sess = self._requests_session_from_driver()
                    r = sess.get(href, timeout=20)
                    content_type = r.headers.get("Content-Type", "").lower()
                    self.logger.info(f"ğŸ“„ å›æ‡‰ Content-Type: {content_type}, å…§å®¹é•·åº¦: {len(r.content)} bytes")

                    # å¦‚æœå›æ‡‰æˆåŠŸä¸”æœ‰å…§å®¹ï¼Œå°±å˜—è©¦è§£æ (ä¸é™åˆ¶ Content-Type)
                    if r.status_code == 200 and len(r.content) > 0:
                        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                        csv_path = os.path.join(self.download_dir, f"mops_{ts}.csv")
                        with open(csv_path, "wb") as f:
                            f.write(r.content)
                        self.logger.info(f"âœ… ä»¥ requests ä¸‹è¼‰æª”æ¡ˆæˆåŠŸ: {os.path.basename(csv_path)}")
                        return self._read_and_filter_csv(csv_path)
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ç›´æ¥è«‹æ±‚ CSV å¤±æ•—: {e}")

        # 3) æ²’æœ‰ hrefï¼ˆæˆ– requests å¤±æ•—ï¼‰â†’ é€€å›é»æ“Š + ç›®éŒ„ç›£çœ‹
        try:
            target = candidates[0]
            self.driver.execute_script("arguments[0].scrollIntoView(true);", target)
            time.sleep(0.5)
            try:
                self.driver.execute_script("arguments[0].click();", target)
            except:
                target.click()
            self.logger.info("ğŸ–±ï¸ å·²é»æ“Šä¸‹è¼‰CSVæŒ‰éˆ•ï¼Œé–‹å§‹ç›£çœ‹ä¸‹è¼‰è³‡æ–™å¤¾ï¼ˆ30ç§’ï¼‰...")
        except Exception as e:
            self.logger.error(f"âŒ é»æ“Šä¸‹è¼‰CSVå¤±æ•—: {e}")
            return None

        # 4) ç›£çœ‹ 30 ç§’ï¼Œæ¥å—ä»»æ„æ–°æª”ï¼ˆé .crdownloadï¼ŒåŒ…å«ç„¡å‰¯æª”åæª”æ¡ˆï¼‰
        latest_file = None
        start = time.time()
        while time.time() - start < 30:
            time.sleep(1)
            files = [f for f in glob.glob(os.path.join(self.download_dir, "*")) if not f.endswith(".crdownload")]
            if files:
                latest = max(files, key=os.path.getmtime)
                # é¿å…æŠŠå¾ˆèˆŠçš„æª”ç•¶æˆæ–°ä¸‹è¼‰
                if time.time() - os.path.getmtime(latest) < 60:
                    latest_file = latest
                    self.logger.info(f"ğŸ“ åµæ¸¬åˆ°æ–°æª”æ¡ˆ: {os.path.basename(latest_file)} (æª”æ¡ˆå¤§å°: {os.path.getsize(latest_file)} bytes)")
                    break
        if not latest_file:
            self.logger.warning("âš ï¸ ä¸‹è¼‰è¶…æ™‚æˆ–ç„¡æ–°æª”ï¼Œæ”¾æ£„ CSV æµç¨‹")
            return None

        self.logger.info(f"âœ… ä½¿ç”¨ Python engine + on_bad_lines='skip' è§£ææª”æ¡ˆ")
        return self._read_and_filter_csv(latest_file)

    def _read_and_filter_csv(self, path):
        import csv
        import re
        import pandas as pd

        # ---- A. è®€æª” & ç·¨ç¢¼å®¹éŒ¯ ----
        encodings = ["utf-8-sig", "utf-8", "big5", "cp950"]
        text = None
        last_err = None
        for enc in encodings:
            try:
                with open(path, "r", encoding=enc, errors="replace") as f:
                    text = f.read()
                if text:
                    self.logger.info(f"ğŸ”¤ æˆåŠŸä»¥ {enc} ç·¨ç¢¼è®€å–æª”æ¡ˆ")
                    break
            except Exception as e:
                last_err = e
                continue
        if not text:
            self.logger.error(f"âŒ ç„¡æ³•ä»¥å¸¸è¦‹ç·¨ç¢¼è®€å–æª”æ¡ˆ: {last_err}")
            return None

        # æ¸…ç† BOM/å¥‡æ€ªæ§åˆ¶å­—å…ƒ
        text = text.replace("\ufeff", "")
        text = text.replace("\x00", "")

        # ---- B. å°‹æ‰¾çœŸæ­£è¡¨é ­æ‰€åœ¨è¡Œï¼ˆåŒ…å«ã€Œå§“åã€èˆ‡ã€Œç›®å‰æŒè‚¡ã€é—œéµè©çš„è¡Œï¼‰ ----
        lines = [ln.strip() for ln in text.splitlines() if ln.strip() != ""]
        header_idx = None
        header_line = None
        for i, ln in enumerate(lines[:100]):  # åªåœ¨å‰100è¡Œæ‰¾è¡¨é ­
            if ("å§“å" in ln or "åç¨±" in ln) and ("ç›®å‰æŒè‚¡" in ln  or "ç›®å‰æŒè‚¡(è‚¡)" in ln):
                header_idx = i
                header_line = ln
                self.logger.info(f"ğŸ¯ åœ¨ç¬¬{i+1}è¡Œæ‰¾åˆ°è¡¨é ­: {ln[:100]}")
                break
        if header_idx is None:
            # è‹¥æ‰¾ä¸åˆ°ï¼Œé€€è€Œæ±‚å…¶æ¬¡ï¼šæ‰¾åˆ°ç¬¬ä¸€è¡Œè‡³å°‘åŒ…å«å…©å€‹æ¬„ä½åˆ†éš”ç¬¦çš„è¡Œ
            for i, ln in enumerate(lines[:100]):
                if ln.count(",") >= 1 or ln.count(";") >= 1 or ln.count("\t") >= 1:
                    header_idx = i
                    header_line = ln
                    self.logger.info(f"ğŸ“Š åœ¨ç¬¬{i+1}è¡Œæ‰¾åˆ°å¯èƒ½çš„è¡¨é ­: {ln[:100]}")
                    break
        if header_idx is None:
            self.logger.error("âŒ æ‰¾ä¸åˆ°è¡¨é ­åˆ—ï¼Œç„¡æ³•è§£æ CSV")
            return None

        data_str = "\n".join(lines[header_idx:])

        # ---- C. è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ ----
        dialect = None
        try:
            dialect = csv.Sniffer().sniff(data_str.splitlines()[0] + "\n" + data_str.splitlines()[1])
            delimiter = dialect.delimiter
            self.logger.info(f"ğŸ” è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦: '{delimiter}'")
        except Exception:
            # æ‰‹å‹•çŒœæ¸¬ï¼šå„ªå…ˆ , ; \t
            if header_line.count(",") >= 1:
                delimiter = ","
            elif header_line.count(";") >= 1:
                delimiter = ";"
            elif header_line.count("\t") >= 1:
                delimiter = "\t"
            else:
                # æœ€å¾Œä¿åº•ï¼šé€—è™Ÿ
                delimiter = ","
            self.logger.info(f"ğŸ” æ‰‹å‹•åˆ¤æ–·åˆ†éš”ç¬¦: '{delimiter}'")

        # ---- D. å¤šç­–ç•¥è®€å– pandas ----
        candidates = []
        # ç­–ç•¥1ï¼šè®“ pandas è‡ªå‹•åˆ¤æ–·ï¼ˆpython engine + on_bad_lines='skip'ï¼‰
        try:
            df1 = pd.read_csv(
                pd.io.common.StringIO(data_str),
                sep=delimiter if delimiter != "," else None,  # é€—è™Ÿæ™‚è®“ sniff æ±ºå®š
                engine="python",
                on_bad_lines="skip"
            )
            if df1 is not None and not df1.empty:
                candidates.append(df1)
                self.logger.info(f"âœ… ç­–ç•¥1æˆåŠŸ: {len(df1)} è¡Œ Ã— {len(df1.columns)} æ¬„")
        except Exception as e:
            self.logger.warning(f"âš ï¸ è®€å–ç­–ç•¥1å¤±æ•—: {e}")

        # ç­–ç•¥2ï¼šæ˜ç¢ºæŒ‡å®š sep
        try:
            df2 = pd.read_csv(pd.io.common.StringIO(data_str), sep=delimiter, engine="python", on_bad_lines="skip")
            if df2 is not None and not df2.empty:
                candidates.append(df2)
                self.logger.info(f"âœ… ç­–ç•¥2æˆåŠŸ: {len(df2)} è¡Œ Ã— {len(df2.columns)} æ¬„")
        except Exception as e:
            self.logger.warning(f"âš ï¸ è®€å–ç­–ç•¥2å¤±æ•—: {e}")

        # ç­–ç•¥3ï¼šè‹¥æ¬„ä½ä»äº‚ï¼Œå…ˆç”¨ csv.reader è§£ææˆ rowsï¼Œå†æ‰‹å·¥è®Š DataFrame
        if not candidates:
            try:
                reader = csv.reader(pd.io.common.StringIO(data_str), delimiter=delimiter)
                rows = [row for row in reader if any(cell.strip() for cell in row)]
                # ä»¥ç¬¬ä¸€åˆ—ç‚ºæ¬„åï¼ˆè‹¥ç¬¬ä¸€åˆ—ä¸æ˜¯ä¸­æ–‡æ¬„åï¼Œå¾Œé¢æœƒå†é‡å‘½åï¼‰
                if len(rows) >= 2:
                    header = rows[0]
                    body = rows[1:]
                    df3 = pd.DataFrame(body, columns=header)
                    candidates.append(df3)
                    self.logger.info(f"âœ… ç­–ç•¥3æˆåŠŸ: {len(df3)} è¡Œ Ã— {len(df3.columns)} æ¬„")
            except Exception as e:
                self.logger.warning(f"âš ï¸ è®€å–ç­–ç•¥3å¤±æ•—: {e}")

        if not candidates:
            self.logger.error("âŒ æ‰€æœ‰ CSV è®€å–ç­–ç•¥å‡å¤±æ•—")
            return None

        # ---- E. å˜—è©¦å¾å€™é¸ df ä¸­æŒ‘å‡ºå«é—œéµæ¬„ä½è€… ----
        def _pick_columns(df):
            cols = list(map(str, df.columns))
            # æ¸…ç†æ¬„åç©ºç™½
            df = df.rename(columns={c: str(c).strip() for c in df.columns})

            name_col = next((c for c in df.columns if any(k in str(c) for k in ["å§“å","åç¨±","å§“å/åç¨±","è‘£ç›£äº‹å§“å"])), None)
            hold_col = next((c for c in df.columns if any(k in str(c) for k in ["ç›®å‰æŒè‚¡","ç›®å‰æŒè‚¡æ•¸","ç›®å‰æŒè‚¡(è‚¡)","ç¾æœ‰æŒè‚¡"])), None)

            # è‹¥ç¬¬ä¸€åˆ—å…¶å¯¦æ˜¯è¡¨é ­ï¼Œæ¬„ååœ¨ç¬¬ä¸€åˆ—å…§å®¹ï¼Œå†æå‡ä¸€è¡Œç‚ºæ¬„å
            if not name_col or not hold_col:
                if len(df) >= 1:
                    first_row = df.iloc[0].astype(str).tolist()
                    if any("å§“å" in x or "åç¨±" in x for x in first_row):
                        df2 = df[1:].copy()
                        df2.columns = first_row
                        df = df2
                        name_col = next((c for c in df.columns if any(k in str(c) for k in ["å§“å","åç¨±","å§“å/åç¨±","è‘£ç›£äº‹å§“å"])), None)
                        hold_col = next((c for c in df.columns if any(k in str(c) for k in ["ç›®å‰æŒè‚¡","ç›®å‰æŒè‚¡æ•¸","ç›®å‰æŒè‚¡(è‚¡)","ç¾æœ‰æŒè‚¡"])), None)

            return df, name_col, hold_col

        chosen = None
        for i, df in enumerate(candidates):
            df2, name_col, hold_col = _pick_columns(df)
            self.logger.info(f"ğŸ“‹ å€™é¸{i+1}: å§“åæ¬„='{name_col}', æŒè‚¡æ¬„='{hold_col}'")
            if name_col and hold_col:
                chosen = (df2, name_col, hold_col)
                self.logger.info(f"âœ… é¸ä¸­å€™é¸{i+1}")
                break

        if not chosen:
            # å†å˜—è©¦æŠŠæ‰€æœ‰æ¬„å/å…§å®¹å»ç©ºç™½å¾Œé‡è©¦ä¸€æ¬¡
            for i, df in enumerate(candidates):
                df.columns = [str(c).strip() for c in df.columns]
                df2, name_col, hold_col = _pick_columns(df)
                if name_col and hold_col:
                    chosen = (df2, name_col, hold_col)
                    self.logger.info(f"âœ… æ¸…ç†ç©ºç™½å¾Œé¸ä¸­å€™é¸{i+1}")
                    break

        if not chosen:
            self.logger.error("âŒ ç„¡æ³•è­˜åˆ¥ã€Œå§“åã€èˆ‡ã€Œç›®å‰æŒè‚¡ã€æ¬„ä½")
            return None

        df, name_col, hold_col = chosen
        out = df[[name_col, hold_col]].copy()
        out.columns = ["å§“å", "ç›®å‰æŒè‚¡"]

        # å»æ‰æ˜é¡¯çš„è¡¨é ­/ç©ºç™½åˆ—
        out = out.dropna(subset=["å§“å"])
        out = out[~out["å§“å"].astype(str).str.contains("å§“å|åç¨±")]
        out["ç›®å‰æŒè‚¡"] = out["ç›®å‰æŒè‚¡"].astype(str).str.strip()
        out = out.drop_duplicates(subset=["å§“å"])

        self.logger.info(f"âœ… CSV æ•¸æ“šè™•ç†å®Œæˆï¼š{len(out)} ç­†")
        return out if not out.empty else None

    def extract_data_from_divs(self, stock_code):
        """å¾ div/span å€å¡Šæå–å§“åå’Œç›®å‰æŒè‚¡æ•¸æ“š"""
        try:
            self.logger.info(f"ğŸ” å˜—è©¦å¾ div/span å€å¡Šæå–è‚¡ç¥¨ {stock_code} çš„æ•¸æ“š")

            # ç­‰å¾…æ•¸æ“šå®Œå…¨åŠ è¼‰
            time.sleep(3)

            # å°‹æ‰¾æ‰€æœ‰åŒ…å«ã€Œå§“åï¼šã€çš„å…ƒç´ 
            name_elements = self.driver.find_elements(By.XPATH, "//*[contains(text(), 'å§“åï¼š')]")
            self.logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(name_elements)} å€‹åŒ…å«ã€Œå§“åï¼šã€çš„å…ƒç´ ")

            if not name_elements:
                self.logger.info("â„¹ï¸ æœªæ‰¾åˆ°åŒ…å«ã€Œå§“åï¼šã€çš„å…ƒç´ ï¼Œå°‡å˜—è©¦è¡¨æ ¼è§£æ")
                return None

            extracted_data = []

            for name_element in name_elements:
                try:
                    # æå–å§“å
                    name_text = name_element.text.strip()
                    if "å§“åï¼š" in name_text:
                        name = name_text.split("å§“åï¼š")[1].strip()
                        if not name:
                            continue

                        # å°‹æ‰¾å°æ‡‰çš„ã€Œç›®å‰æŒè‚¡ï¼šã€å…ƒç´ 
                        holdings = None

                        # ç­–ç•¥1: åœ¨åŒä¸€å€‹çˆ¶å…ƒç´ ä¸­å°‹æ‰¾
                        parent = name_element.find_element(By.XPATH, "./..")
                        holdings_elements = parent.find_elements(By.XPATH, ".//*[contains(text(), 'ç›®å‰æŒè‚¡ï¼š')]")

                        if holdings_elements:
                            holdings_text = holdings_elements[0].text.strip()
                            if "ç›®å‰æŒè‚¡ï¼š" in holdings_text:
                                holdings = holdings_text.split("ç›®å‰æŒè‚¡ï¼š")[1].strip()
                        else:
                            # ç­–ç•¥2: åœ¨æ•´å€‹é é¢ä¸­å°‹æ‰¾ç·Šé„°çš„ã€Œç›®å‰æŒè‚¡ï¼šã€å…ƒç´ 
                            following_elements = name_element.find_elements(By.XPATH, "./following::*[contains(text(), 'ç›®å‰æŒè‚¡ï¼š')][1]")
                            if following_elements:
                                holdings_text = following_elements[0].text.strip()
                                if "ç›®å‰æŒè‚¡ï¼š" in holdings_text:
                                    holdings = holdings_text.split("ç›®å‰æŒè‚¡ï¼š")[1].strip()
                            else:
                                # ç­–ç•¥3: å°‹æ‰¾ä¸‹ä¸€å€‹å…„å¼Ÿå…ƒç´ æˆ–é„°è¿‘å…ƒç´ 
                                siblings = name_element.find_elements(By.XPATH, "./following-sibling::*")
                                for sibling in siblings[:5]:  # åªæª¢æŸ¥å‰5å€‹å…„å¼Ÿå…ƒç´ 
                                    if "ç›®å‰æŒè‚¡ï¼š" in sibling.text:
                                        holdings_text = sibling.text.strip()
                                        holdings = holdings_text.split("ç›®å‰æŒè‚¡ï¼š")[1].strip()
                                        break

                        if name and holdings is not None:
                            extracted_data.append({
                                "å§“å": name,
                                "ç›®å‰æŒè‚¡": holdings
                            })
                            self.logger.info(f"   âœ… æå–æˆåŠŸ: å§“å={name}, ç›®å‰æŒè‚¡={holdings}")
                        else:
                            self.logger.info(f"   âš ï¸ ç„¡æ³•æ‰¾åˆ°å°æ‡‰çš„æŒè‚¡æ•¸æ“š: å§“å={name}")

                except Exception as e:
                    self.logger.info(f"   âš ï¸ è™•ç†å…ƒç´ æ™‚å‡ºéŒ¯: {e}")
                    continue

            if extracted_data:
                df = pd.DataFrame(extracted_data)
                self.logger.info(f"âœ… å¾ div/span æˆåŠŸæå– {len(extracted_data)} è¡Œæ•¸æ“š")
                return df
            else:
                self.logger.info("â„¹ï¸ div/span å€å¡Šä¸­æœªæå–åˆ°æœ‰æ•ˆæ•¸æ“š")
                return None

        except Exception as e:
            self.logger.error(f"âŒ div/span æ•¸æ“šæå–å¤±æ•—: {e}")
            return None

    def extract_data_from_table(self, stock_code):
        """å¾è¡¨æ ¼æå–å§“åå’Œç›®å‰æŒè‚¡æ•¸æ“šï¼ˆåŸå§‹é‚è¼¯ï¼‰"""
        try:
            self.logger.info(f"ğŸ“Š å¾è¡¨æ ¼æå–è‚¡ç¥¨ {stock_code} çš„æ•¸æ“š")

            # å¯»æ‰¾æ•°æ®è¡¨æ ¼
            tables = self.driver.find_elements(By.TAG_NAME, "table")
            self.logger.info(f"ğŸ“‹ é¡µé¢ä¸­æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")

            if not tables:
                self.logger.warning("âš ï¸ é¡µé¢ä¸­æ²¡æœ‰æ‰¾åˆ°è¡¨æ ¼")
                return None

            # é€‰æ‹©æœ€ä½³è¡¨æ ¼
            target_table = None
            max_score = 0

            for i, table in enumerate(tables):
                try:
                    table_text = table.text
                    keywords = ["å§“å", "æŒè‚¡", "è‘£äº‹", "ç›£äº‹", "ç›®å‰", "ç¾ä»»"]
                    score = sum(1 for keyword in keywords if keyword in table_text)

                    rows = table.find_elements(By.TAG_NAME, "tr")
                    if len(rows) < 2:
                        score = 0

                    self.logger.info(f"   è¡¨æ ¼{i+1}: è¯„åˆ†{score}, è¡Œæ•°{len(rows)}")

                    if score > max_score and score >= 2:
                        max_score = score
                        target_table = table

                except:
                    continue

            if not target_table:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°åŒ…å«è‚¡ä¸œæ•°æ®çš„è¡¨æ ¼")
                return None

            # æå–è¡¨æ ¼æ•°æ®
            rows = target_table.find_elements(By.TAG_NAME, "tr")
            headers = []
            data_rows = []

            for row in rows:
                try:
                    cells = row.find_elements(By.TAG_NAME, "td")
                    if not cells:
                        cells = row.find_elements(By.TAG_NAME, "th")
                        if cells and not headers:
                            headers = [cell.text.strip() for cell in cells if cell.text.strip()]

                    if len(cells) >= 2 and any(cell.text.strip() for cell in cells):
                        row_data = [cell.text.strip() for cell in cells]
                        data_rows.append(row_data)

                except:
                    continue

            if not data_rows:
                self.logger.warning("âš ï¸ æ²¡æœ‰æå–åˆ°æœ‰æ•ˆæ•°æ®")
                return None

            self.logger.info(f"ğŸ“Š è¡¨å¤´: {headers}")
            self.logger.info(f"ğŸ“Š æ•°æ®è¡Œ: {len(data_rows)}")

            # æ™ºèƒ½è¯†åˆ«å§“åå’ŒæŒè‚¡åˆ—
            name_col_index = None
            holdings_col_index = None

            # å¯»æ‰¾å§“ååˆ—
            for i, header in enumerate(headers):
                if any(keyword in header for keyword in ["å§“å", "åç¨±"]):
                    name_col_index = i
                    break
            if name_col_index is None and len(headers) >= 2:
                name_col_index = 1

            # å¯»æ‰¾æŒè‚¡åˆ—
            for i, header in enumerate(headers):
                if any(keyword in header for keyword in ["ç›®å‰æŒè‚¡", "ç›®å‰"]):
                    holdings_col_index = i
                    break
            if holdings_col_index is None:
                for col in range(2, min(len(headers), 6)):
                    has_numbers = False
                    for row in data_rows[:3]:
                        if col < len(row):
                            cell_text = row[col].replace(',', '').replace(' ', '')
                            if cell_text.isdigit() and len(cell_text) > 2:
                                has_numbers = True
                                break
                    if has_numbers:
                        holdings_col_index = col
                        break

            if name_col_index is None or holdings_col_index is None:
                self.logger.error(f"âŒ æ— æ³•è¯†åˆ«å§“ååˆ—({name_col_index})æˆ–æŒè‚¡åˆ—({holdings_col_index})")
                return None

            # æå–æ•°æ®
            extracted_data = []
            for row in data_rows:
                try:
                    if name_col_index < len(row) and holdings_col_index < len(row):
                        name = row[name_col_index].strip()
                        holdings = row[holdings_col_index].strip()

                        if (name and holdings and name not in ["å§“å", "åç¨±"] and
                            not any(keyword in name for keyword in ["è·ç¨±", "å§“å"])):
                            extracted_data.append({
                                "å§“å": name,
                                "ç›®å‰æŒè‚¡": holdings
                            })
                except:
                    continue

            if extracted_data:
                df = pd.DataFrame(extracted_data)
                self.logger.info(f"âœ… å¾è¡¨æ ¼æˆåŠŸæå– {len(extracted_data)} è¡Œæ•°æ®")
                return df
            else:
                self.logger.warning("âš ï¸ è¡¨æ ¼ä¸­æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„å§“åå’ŒæŒè‚¡æ•°æ®")
                return None

        except Exception as e:
            self.logger.error(f"âŒ è¡¨æ ¼æ•°æ®æå–å¤±è´¥: {e}")
            return None

    def extract_name_and_holdings_data(self, stock_code):
        """æå–å§“åå’Œç›®å‰æŒè‚¡æ•°æ®ï¼ˆå„ªå…ˆä½¿ç”¨ div/spanï¼Œå…¶æ¬¡ä½¿ç”¨è¡¨æ ¼ï¼‰"""
        try:
            self.logger.info(f"ğŸ“Š æ­¥éª¤5: æå–è‚¡ç¥¨ {stock_code} çš„å§“åå’ŒæŒè‚¡æ•°æ®")

            # ç­‰å¾…æ•°æ®å®Œå…¨åŠ è½½
            time.sleep(3)

            # éªŒè¯æ˜¯å¦æœ‰æŸ¥è¯¢ç»“æœ
            page_source = self.driver.page_source
            if stock_code not in page_source and "è‚¡ä»½æœ‰é™å…¬å¸" not in page_source:
                self.logger.warning("âš ï¸ é¡µé¢ä¸­å¯èƒ½æ²¡æœ‰æŸ¥è¯¢ç»“æœ")

            # å„ªå…ˆå˜—è©¦å¾ div/span å€å¡Šæå–æ•¸æ“š
            div_data = self.extract_data_from_divs(stock_code)
            if div_data is not None and len(div_data) > 0:
                self.logger.info("âœ… æˆåŠŸå¾ div/span å€å¡Šæå–æ•¸æ“š")
                return div_data

            # å¦‚æœ div/span æå–å¤±æ•—ï¼Œå›åˆ°åŸå§‹çš„è¡¨æ ¼æå–é‚è¼¯
            self.logger.info("ğŸ“‹ div/span æå–ç„¡æ•¸æ“šï¼Œå˜—è©¦è¡¨æ ¼æå–")
            table_data = self.extract_data_from_table(stock_code)
            if table_data is not None and len(table_data) > 0:
                self.logger.info("âœ… æˆåŠŸå¾è¡¨æ ¼æå–æ•¸æ“š")
                return table_data

            self.logger.warning("âš ï¸ æ‰€æœ‰æå–æ–¹å¼éƒ½æœªèƒ½ç²å¾—æœ‰æ•ˆæ•¸æ“š")
            return None

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®æå–å¤±è´¥: {e}")
            return None

    def process_single_stock(self, stock_code, is_retry=False):
        """å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å®Œæ•´æµç¨‹"""
        try:
            retry_msg = "âš ï¸ Chrome å´©æ½°ï¼Œè‡ªå‹•é‡è©¦" if is_retry else ""
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ“ˆ å¼€å§‹å¤„ç†è‚¡ç¥¨: {stock_code} {retry_msg}")
            self.logger.info(f"{'='*60}")

            # ç¢ºä¿åªæœ‰ä¸€å€‹åˆ†é 
            self.ensure_single_tab()

            # æª¢æŸ¥ç€è¦½å™¨æ˜¯å¦æ­£å¸¸
            if not self.check_driver_alive():
                self.logger.error(f"âŒ ç€è¦½å™¨é©…å‹•å·²æ–·ç·šï¼Œè™•ç†è‚¡ç¥¨ {stock_code} å¤±æ•—")
                return False

            # å¯¼èˆªåˆ°ç›®æ ‡é¡µé¢
            if not self.navigate_to_target_page():
                return False

            # å¯»æ‰¾å¹¶å¡«å†™è¾“å…¥æ¡†
            if not self.find_and_fill_company_input(stock_code):
                return False

            # ç‚¹å‡»æŸ¥è¯¢æŒ‰é’®
            if not self.click_query_button():
                return False

            # æ•¸æ“šæå–ï¼ˆå„ªå…ˆé †åºï¼šCSVä¸‹è¼‰ > div/spanè§£æ > è¡¨æ ¼è§£æï¼‰
            data = None

            # æ­¥éª¤4a: ä¼˜å…ˆå°è¯•CSVä¸‹è½½
            data = self.download_csv_and_parse()
            if data is not None and len(data) > 0:
                # åœ¨å­˜å…¥ self.all_data ä¹‹å‰ï¼ŒåŠ å…¥è‚¡ç¥¨ä»£è™Ÿæ¬„ä½ï¼ˆå¦‚æœå°šæœªæ’å…¥ï¼‰
                if "è‚¡ç¥¨ä»£è™Ÿ" not in data.columns:
                    data.insert(0, "è‚¡ç¥¨ä»£è™Ÿ", stock_code)
                self.all_data[stock_code] = data
                self.logger.info(f"âœ… è‚¡ç¥¨ {stock_code} é€šéCSVä¸‹è¼‰è™•ç†æˆåŠŸ")
                return True

            # æ­¥éª¤4b: å¦‚æœCSVä¸‹è½½å¤±è´¥ï¼Œé€€å›åˆ°åŸæœ‰çš„è§£æé€»è¾‘
            self.logger.info("ğŸ“‹ CSVä¸‹è¼‰å¤±æ•—ï¼Œä½¿ç”¨å‚™æ´è§£ææ–¹å¼")
            data = self.extract_name_and_holdings_data(stock_code)
            if data is not None and len(data) > 0:
                # åœ¨å­˜å…¥ self.all_data ä¹‹å‰ï¼ŒåŠ å…¥è‚¡ç¥¨ä»£è™Ÿæ¬„ä½ï¼ˆå¦‚æœå°šæœªæ’å…¥ï¼‰
                if "è‚¡ç¥¨ä»£è™Ÿ" not in data.columns:
                    data.insert(0, "è‚¡ç¥¨ä»£è™Ÿ", stock_code)
                self.all_data[stock_code] = data
                self.logger.info(f"âœ… è‚¡ç¥¨ {stock_code} é€šéå‚™æ´è§£æè™•ç†æˆåŠŸ")
                return True
            else:
                self.logger.error(f"âŒ è‚¡ç¥¨ {stock_code} æ‰€æœ‰æ•¸æ“šæå–æ–¹å¼éƒ½å¤±æ•—")
                return False

        except (WebDriverException, Exception) as e:
            if "chrome not reachable" in str(e).lower() or "session deleted" in str(e).lower():
                self.logger.error(f"âš ï¸ Chrome å´©æ½°æª¢æ¸¬åˆ°: {e}")
            else:
                self.logger.error(f"âŒ å¤„ç†è‚¡ç¥¨ {stock_code} å¼‚å¸¸: {e}")
            return False

    def save_to_excel(self, output_path, make_per_sheet=False):
        """ä¿å­˜åˆ°Excel"""
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # åˆä½µè¡¨
                merged = []
                for stock_code, df in self.all_data.items():
                    merged.append(df[["è‚¡ç¥¨ä»£è™Ÿ", "å§“å", "ç›®å‰æŒè‚¡"]].copy())

                if merged:
                    merged_df = pd.concat(merged, ignore_index=True)
                    merged_df.to_excel(writer, sheet_name="åˆä½µ", index=False)

                    # ç°¡å–®æ ¼å¼
                    ws = writer.sheets["åˆä½µ"]
                    from openpyxl.styles import Font, PatternFill, Alignment
                    header_font = Font(bold=True, color="FFFFFF")
                    header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                    for cell in ws[1]:
                        cell.font = header_font
                        cell.fill = header_fill
                        cell.alignment = Alignment(horizontal="center")
                    ws.column_dimensions['A'].width = 14  # è‚¡ç¥¨ä»£è™Ÿ
                    ws.column_dimensions['B'].width = 30  # å§“å
                    ws.column_dimensions['C'].width = 20  # ç›®å‰æŒè‚¡

                # ä¾ä»£è™Ÿå„è‡ªä¸€å¼µåˆ†é ï¼ˆå¯é¸ï¼‰
                if make_per_sheet:
                    for stock_code, data in self.all_data.items():
                        sheet_name = f"è‚¡ç¥¨_{stock_code}"[:31]  # Excel åç¨±é•·åº¦é™åˆ¶
                        data.to_excel(writer, sheet_name=sheet_name, index=False)

                        # æ ¼å¼åŒ–
                        worksheet = writer.sheets[sheet_name]
                        from openpyxl.styles import Font, PatternFill, Alignment

                        header_font = Font(bold=True, color="FFFFFF")
                        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")

                        for cell in worksheet[1]:
                            cell.font = header_font
                            cell.fill = header_fill
                            cell.alignment = Alignment(horizontal="center")

                        worksheet.column_dimensions['A'].width = 14  # è‚¡ç¥¨ä»£è™Ÿ
                        worksheet.column_dimensions['B'].width = 30  # å§“å
                        worksheet.column_dimensions['C'].width = 20  # ç›®å‰æŒè‚¡

                if self.failed_codes:
                    pd.DataFrame({"å¤±æ•—çš„è‚¡ç¥¨ä»£è™Ÿ": self.failed_codes}).to_excel(writer, sheet_name="å¤±æ•—è¨˜éŒ„", index=False)

            self.logger.info(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_path}")
            return True

        except Exception as e:
            self.logger.error(f"âŒ Excelä¿å­˜å¤±è´¥: {e}")
            return False

    def run_batch(self, codes_file="è‚¡ç¥¨ä»£è™Ÿ.txt", make_per_sheet=False, throttle_sec=1.5, retry=1):
        """æ‰¹æ¬¡è™•ç†è‚¡ç¥¨æ¸…å–®"""
        try:
            self.logger.info("="*80)
            self.logger.info("ğŸš€ æ‰¹æ¬¡æŠ“å–é–‹å§‹")
            self.logger.info("="*80)

            if not self.init_driver():
                return False

            codes = self.read_stock_codes(codes_file)
            if not codes:
                self.logger.error("âŒ æ²’æœ‰å¯ç”¨çš„ä»£è™Ÿ")
                return False

            for idx, code in enumerate(codes, 1):
                ok = False
                for r in range(retry + 1):
                    self.logger.info(f"\n[{idx}/{len(codes)}] â–¶ï¸ è™•ç† {code}ï¼ˆé‡è©¦ {r}/{retry}ï¼‰")
                    ok = self.process_single_stock(code)
                    if ok:
                        break
                    time.sleep(2)
                if not ok:
                    self.failed_codes.append(code)
                time.sleep(throttle_sec)  # ç¯€æµï¼Œé¿å…éå¿«

            if self.all_data:
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                out = f"è‘£ç›£äº‹æŒè‚¡_æ‰¹æ¬¡_{ts}.xlsx"
                self.save_to_excel(out, make_per_sheet=make_per_sheet)
                self.logger.info(f"ğŸ¯ æ‰¹æ¬¡å®Œæˆï¼æˆåŠŸ {len(self.all_data)} æª”ï¼Œå¤±æ•— {len(self.failed_codes)} æª”")
                return True
            else:
                self.logger.error("âŒ ç„¡ä»»ä½•æˆåŠŸè³‡æ–™")
                return False

        except Exception as e:
            self.logger.error(f"âŒ æ‰¹æ¬¡åŸ·è¡Œç™¼ç”Ÿä¾‹å¤–: {e}")
            return False
        finally:
            if self.driver:
                self.driver.quit()

    def run_batch_resume(self, codes_file="è‚¡ç¥¨ä»£è™Ÿ.txt", out_path=None, throttle_sec=1.5, retry=1):
        """æ‰¹æ¬¡è™•ç†è‚¡ç¥¨æ¸…å–®ï¼ˆå¯çºŒè·‘ç‰ˆæœ¬ï¼‰"""
        import os
        from datetime import datetime

        self.logger.info("="*80)
        self.logger.info("ğŸš€ æ‰¹æ¬¡æŠ“å–ï¼ˆå¯çºŒè·‘ï¼‰é–‹å§‹")
        self.logger.info("="*80)

        if not self.init_driver():
            return False

        codes = self.read_stock_codes(codes_file)
        if not codes:
            self.logger.error("âŒ æ²’æœ‰å¯ç”¨çš„ä»£è™Ÿ")
            return False

        done = self.load_processed_codes()
        pending = [c for c in codes if c not in done]
        self.logger.info(f"âœ… å·²å®Œæˆ {len(done)} æª”ï¼Œå¾…è™•ç† {len(pending)} æª”")

        if out_path is None:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            out_path = f"è‘£ç›£äº‹æŒè‚¡_åˆä½µ_{ts}.xlsx"

        success_cnt = 0
        self.processed_count = 0  # é‡ç½®è¨ˆæ•¸å™¨

        for idx, code in enumerate(pending, 1):
            # æ¯è™•ç† 200 å€‹è‚¡ç¥¨å°±è‡ªå‹•é‡å•Ÿç€è¦½å™¨
            if self.processed_count > 0 and self.processed_count % 200 == 0:
                self.logger.info(f"â™»ï¸ å·²è™•ç† {self.processed_count} å€‹è‚¡ç¥¨ï¼Œè‡ªå‹•é‡å•Ÿç€è¦½å™¨")
                if not self.restart_driver():
                    self.logger.error("â™»ï¸ ç€è¦½å™¨é‡å•Ÿå¤±æ•—ï¼Œçµ‚æ­¢ç¨‹åº")
                    break

            ok = False
            for r in range(retry + 1):
                is_retry = r > 0
                if is_retry:
                    self.logger.info(f"[{idx}/{len(pending)}] â–¶ï¸ {code}ï¼ˆé‡è©¦ {r}/{retry}ï¼‰")
                else:
                    self.logger.info(f"[{idx}/{len(pending)}] â–¶ï¸ {code}")

                # æª¢æŸ¥ç€è¦½å™¨ç‹€æ…‹ï¼Œå¦‚æœå´©æ½°å‰‡é‡å•Ÿ
                if not self.check_driver_alive():
                    self.logger.warning(f"âš ï¸ Chrome å´©æ½°æª¢æ¸¬åˆ°ï¼Œæ­£åœ¨é‡å•Ÿç€è¦½å™¨...")
                    if not self.restart_driver():
                        self.logger.error(f"âš ï¸ Chrome é‡å•Ÿå¤±æ•—ï¼Œè·³éè‚¡ç¥¨ {code}")
                        break

                try:
                    ok = self.process_single_stock(code, is_retry=is_retry)  # å…§å« CSV/å‚™æ´è§£æ
                    if ok and code in self.all_data:
                        # ç«‹åˆ»å¯«å…¥ Excelï¼ˆåˆä½µè¡¨ï¼‰ï¼Œä¸¦æ¨™è¨˜ processed
                        df = self.all_data[code][["è‚¡ç¥¨ä»£è™Ÿ","å§“å","ç›®å‰æŒè‚¡"]].copy()
                        self.append_to_master_excel(out_path, df)
                        self.append_processed_code(code)
                        # é‡‹æ”¾è©²ä»£è™Ÿçš„æš«å­˜ä»¥çœè¨˜æ†¶é«”
                        del self.all_data[code]
                        success_cnt += 1
                        self.processed_count += 1
                        break
                except (WebDriverException, Exception) as e:
                    if "chrome not reachable" in str(e).lower() or "session deleted" in str(e).lower():
                        self.logger.warning(f"âš ï¸ Chrome å´©æ½°ï¼Œæº–å‚™é‡è©¦: {e}")
                        if not self.restart_driver():
                            self.logger.error(f"âš ï¸ Chrome é‡å•Ÿå¤±æ•—")
                            break
                    else:
                        self.logger.error(f"âŒ è™•ç†è‚¡ç¥¨ {code} æ™‚ç™¼ç”Ÿç•°å¸¸: {e}")
                        break

                time.sleep(2)

            if not ok:
                self.failed_codes.append(code)

            time.sleep(throttle_sec)

        # æœ€å¾ŒæŠŠå¤±æ•—æ¸…å–®å¯«å…¥åˆ°åŒä¸€ä»½ Excel çš„ã€Œå¤±æ•—è¨˜éŒ„ã€sheetï¼ˆè¦†è“‹æˆ–æ–°å»ºï¼‰
        try:
            import pandas as pd
            mode = "a" if os.path.exists(out_path) else "w"
            with pd.ExcelWriter(out_path, engine="openpyxl", mode="a" if mode=="a" else "w") as writer:
                if self.failed_codes:
                    pd.DataFrame({"å¤±æ•—çš„è‚¡ç¥¨ä»£è™Ÿ": self.failed_codes}).to_excel(writer, sheet_name="å¤±æ•—è¨˜éŒ„", index=False)
        except Exception as e:
            self.logger.warning(f"âš ï¸ å¯«å…¥å¤±æ•—è¨˜éŒ„æ™‚ç™¼ç”Ÿä¾‹å¤–ï¼š{e}")

        self.logger.info(f"ğŸ¯ å®Œæˆï¼šæˆåŠŸ {success_cnt} æª”ï¼Œå¤±æ•— {len(self.failed_codes)} æª”ï¼›è¼¸å‡ºï¼š{out_path}")
        if self.driver:
            self.driver.quit()
        return success_cnt > 0

    def run_fixed_test(self, stock_codes=['1235']):
        """è¿è¡Œä¿®å¤ç‰ˆæµ‹è¯•"""
        try:
            self.logger.info("=" * 80)
            self.logger.info("ğŸ”§ ä¿®å¤è¾“å…¥æ¡†å®šä½çš„çˆ¬è™«æµ‹è¯•")
            self.logger.info("=" * 80)

            if not self.init_driver():
                return False

            for stock_code in stock_codes:
                success = self.process_single_stock(stock_code)
                if not success:
                    self.failed_codes.append(stock_code)
                time.sleep(3)

            if self.all_data:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"ä¿®å¤ç‰ˆè‚¡ç¥¨æ•°æ®_{timestamp}.xlsx"
                self.save_to_excel(output_file)

                self.logger.info(f"\nğŸ¯ å¤„ç†å®Œæˆ!")
                self.logger.info(f"   æˆåŠŸ: {len(self.all_data)} ä¸ªè‚¡ç¥¨")
                self.logger.info(f"   å¤±è´¥: {len(self.failed_codes)} ä¸ªè‚¡ç¥¨")

            return len(self.all_data) > 0

        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•è¿è¡Œå¼‚å¸¸: {e}")
            return False
        finally:
            if self.driver:
                self.driver.quit()

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--codes-file", default="è‚¡ç¥¨ä»£è™Ÿ.txt")
    parser.add_argument("--out", default=None, help="è¼¸å‡º Excel è·¯å¾‘ï¼›ä¸å¡«å‰‡è‡ªå‹•ä¾æ™‚é–“å‘½å")
    parser.add_argument("--retry", type=int, default=1)
    parser.add_argument("--throttle", type=float, default=1.5)
    args = parser.parse_args()

    print("ğŸ”§ è‚¡ç¥¨çˆ¬èŸ²ï¼ˆé‚Šè·‘é‚Šå¯«ãƒ»å¯çºŒè·‘ï¼‰")
    print("="*50)
    crawler = FixedInputCrawler()
    ok = crawler.run_batch_resume(
        codes_file=args.codes_file,
        out_path=args.out,
        throttle_sec=args.throttle,
        retry=args.retry
    )
    print("\nâœ… å®Œæˆ" if ok else "\nâŒ å¤±æ•—ï¼Œè«‹çœ‹ log")

if __name__ == "__main__":
    main()